#!/usr/bin/env python
# -*- coding:utf-8 -*-


from pyspider.libs.base_handler import *
import re
from pyspider.database.mysql.mysqldb import SQL
import time
import datetime
import random
import os
import urllib2
import json
import  sys
reload(sys)
sys.setdefaultencoding('utf-8')

DIR_PATH='/root/xuguanjun/getimg/taobao/'

class Handler(BaseHandler):
    headers= {
		"Accept":"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
		"Accept-Encoding":"gzip, deflate, sdch",
		"Accept-Language":"zh-CN,zh;q=0.8",
		"Cache-Control":"max-age=0",
		"Connection":"keep-alive",
        "user-agent" :"IUC(U;iOS 5.1.1;Zh-cn;320*480;)/UCWEB8.9.1.271/42/800",
        "cookie":"cookie2=1e5657f6e024208e0ebc54c78a73bdf6; t=0aae94badb3080483a6475aad19dc1f9;  _tb_token_=338eb61903763; "


    }
    
    crawl_config = {
        "headers" : headers,
        "timeout" : 100
    }
    
    def __init__(self):
        #count :  https://fila.m.tmall.com/shop/shop_auction_search.do?style=list&p=1&page_size=0&from=h5&ascid=448441394&scid=448441394
        #https://fila.m.tmall.com/shop/shop_auction_search.htm?sort=d&style=list&ascid=448441394&scid=448441394
        self.base_url = 'https://underarmour.m.tmall.com/shop/shop_auction_search.htm?sort=d&style=list&'
        self.base_count_url = 'https://underarmour.m.tmall.com/shop/shop_auction_search.do?style=list&p=1&page_size=0&from=h5&'
        self.base_code = { 
            "jingshen-trousers" : "870090214" ,            
            "clothes" : "870088872" , 
            "hat-clothes" : "870090220" ,
            "long-T-shirt" : "870088874",
            "T-shirt": "870088873" ,
            "polo" : "870090219" ,
            "trousers" : "870093256",
            "short-trousers" : "870090216",
            "NewGoods" : "1348944166",
        
        }
        self.gettime = time.strftime("%Y-%m-%d", time.localtime()) 
        self.brand = ""
        self.tb = "underarmour"
        self.tbCount = "underarmourCount"      
        self.start = '045000'         
        self.deal=Deal()   


    @every(minutes= 2  , seconds=0)
    @config(age= 60)     
    def on_start(self): 
        if self.checkrun() == 1:
            print 'run'
            pass
        else:
            print 'return'
            return           
        
        for key in self.base_code: 
            i = random.randint(1,300)
            url = "%sascid=%s&scid=%s" % ( self.base_url,self.base_code[key],self.base_code[key])
            #print url;
            self.crawl(url, callback=self.index_page , exetime=time.time()+ i*2 , retries=10, validate_cert=False , fetch_type="js" , js_script='''
               function() {
                 setTimeout("window.scrollTo(0,document.documentElement.scrollHeight)", 16000);
               }
               ''' ,timeout=360,connect_timeout=180, save={'brand':key})
            
    def rematch(self , str):
        x = re.compile(u'男')
        y = re.compile(u'鞋')
        a = x.findall(str)
        b = y.findall(str)
        if len(a) == 0:
            return 0
        if len(b) > 0:
            return 0
        
        return 1            


    def checkrun(self):
        strstart = datetime.datetime.now().strftime('%Y%m%d') + self.start
        strnow = datetime.datetime.now().strftime('%Y%m%d%H%M%S')
        tnow = time.mktime(time.strptime(strnow,'%Y%m%d%H%M%S'))
        tstart = time.mktime(time.strptime(strstart,'%Y%m%d%H%M%S'))
        tend = tstart + 120
        print tnow , tstart  ,tend
        
        if tnow >= tstart and tnow < tend :
            return 1
        else:
            return 0    
    
    


    def index_page(self, response):
        count_url = "%sascid=%s&scid=%s" % ( self.base_count_url,self.base_code[response.save['brand']],self.base_code[response.save['brand']])
        #存数量
        total = self.index_count(count_url)
        
        brandCount = {
            "brand" : response.save['brand'],
            "gettime" :  self.gettime , 
            "count" : total ,
            "url" : response.url
        }
        sql = SQL()
        sql.insert(self.tbCount,**brandCount) 

        
    
        if response.save['brand'] == 'NewGoods':
            cnum = 50
        else:
            cnum = 30           
        count = 0         
        for each in response.doc('.list_item').items():
            
            if self.rematch(each.text()) == 0:
                continue
                
            if count >= cnum:
                break
            i = random.randint(1,300)
            url = each.attr.href.split('&')[0]
            print url
            self.crawl(url, callback=self.detail_page, exetime=time.time()+ i*7  , retries=10, validate_cert=False , fetch_type="js" , js_script='''
               function() {
                 parent.location.reload();
                 setTimeout("window.scrollTo(0,document.documentElement.scrollHeight)", 32000);
                 
               }
               ''' ,js_run_at="document-end" ,load_images='false' , timeout=360,connect_timeout=180, save = {'brand' : response.save['brand']})
            count += 1

    
   
    
    
           
    def index_count(self , url): 
        response = urllib2.urlopen(url)
        cont = response.read()
        # "sellCount\":\"10\"
        print cont
        regex=re.compile('"total_results":"(\d+)"')
        total = regex.findall(cont)[0]  
        return total
        
        

  
    def only_deal(self , goodsid):
        #goodsid = 564795256715
        url = 'https://h5api.m.taobao.com/h5/mtop.taobao.detail.getdetail/6.0/?data=%7B%22itemNumId%22%3A%22'+ goodsid +'%22%7D'
        print url
        msales = 0
        name = ''
        promotion_price = 0
        mprice = 0

        response = urllib2.urlopen(url)
        cont = response.read()
        # "sellCount\":\"10\"
        print cont

        regex=re.compile('\\\\"sellCount\\\\":\\\\"(\d+)\\\\"')
        msales = regex.findall(cont)[0]    

        regex=re.compile('\\\\"title\\\\":\\\\"([^\"|,]*)\\\\"')
        #print regex.findall(cont)
        name = regex.findall(cont)[0]  
        #print name
       
        
        try:
            regex=re.compile('price\\\\":{\\\\"priceText\\\\":\\\\"(\d+)-(\d+)\\\\"')
            promotion_price = regex.findall(cont)[0] 
        except:
            regex=re.compile('\\\\"price\\\\":{\\\\"priceText\\\\":\\\\"([\d|\.]+)\\\\"')
            promotion_price = regex.findall(cont)[0] 
            mprice = regex.findall(cont)[1] 
            #print regex.findall(cont)
                
        if mprice == 0:
            regex=re.compile('\\\\"priceText\\\\":\\\\"(\d+)\\\\"')
            mprice = regex.findall(cont)[0] 
        
        try:
            mprice = mprice.split('.')[0]
        except:
            pass

        if promotion_price == mprice:
            promotion_price = 0        
        
        #print msales , name ,  promotion_price , mprice
        return msales , name ,  promotion_price , mprice 



    def detail_page(self, response):
        print response.url

        mactivity = response.doc('#J_mod9 .cell').text()
        goodsid =  response.url.split('=')[1].split('&')[0]
        msales , name ,  promotion_price , mprice = self.only_deal(goodsid)
        
        if mprice =='':
            raise ValueError('mprice is none')
        if msales =='':
            raise ValueError('msales is none')       
        if len(name) < 5:
            raise ValueError('name len is less')  
        
        dir_path = DIR_PATH + goodsid
        if os.path.exists(dir_path):
            pass
        else:
            dir_path=self.deal.mkDIR(goodsid)
            
            
            
        #imgs=response.doc('.tb-thumb-content img').items()
        imgs=response.doc('#J_mod0 > div > section > div.scroller.preview-scroller   img').items()

        count = 0
        for img in imgs:
            #print img
            url = img.attr("data-src")
            #print url
            if url:
                i = random.randint(1,300)
                #suffix = '430x430q90.jpg'
                #newurl = url[:-12] + suffix
                newurl = 'http:' + url
                filename = str(count) + '.jpg'
                if os.path.exists(dir_path + '/' + filename):
                    pass
                else:
                    dir_path=self.deal.mkDIR(goodsid)               
                    self.crawl(newurl, callback=self.save_img, exetime=time.time()+ i*3  , validate_cert=False , save={'save_path':dir_path,'file_name':filename})
                count += 1
                
        return { 
               "brand" : response.save['brand'] ,
               #"url": response.url[0:50],
               "url" : "https://detail.tmall.com/item.htm?id=" + goodsid ,
               "name" : name.encode('utf-8') ,
               "msales": msales ,
               "mprice": mprice ,
               "promotion_price" : promotion_price ,
               "mactivity": mactivity ,
               "gettime" : self.gettime
        }
 
    def save_img(self,response):
        content=response.content
        dir_path=response.save['save_path']
        file_name=response.save['file_name']
        file_path=dir_path+'/'+file_name
        self.deal.save_Img(content,file_path) 


    def on_result(self,result):
        #print result
        if not result or not result['url'] or not result['name'] :
            return
        sql = SQL()
        sql.insert(self.tb,**result)  
        
        
        
        
        
class Deal:
    def __init__(self):
        self.dir_path=DIR_PATH
        if not self.dir_path.endswith('/'):
            self.dir_path=self.dir_path+'/'
        if not os.path.exists(self.dir_path):
            os.makedirs(self.dir_path)

    def mkDIR(self,name):
        name=name.strip()
        #dir_name=self.dir_path+'/'+name
        dir_name=self.dir_path+name
        exists=os.path.exists(dir_name)
        if not exists:
            os.makedirs(dir_name)
            return dir_name
        else:
            return dir_name

    def save_Img(self,content,file_name):
        file=open(file_name,'wb')
        file.write(content)
        file.close()        
        
        
        
        
        
        
        
        
        